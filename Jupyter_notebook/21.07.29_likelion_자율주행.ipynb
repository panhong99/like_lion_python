{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984acf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense , Conv2D , Dropout , MaxPooling2D , Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator , array_to_img , img_to_array , load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "rc(\"font\" , family = \"AppleGothic\")\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d72e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_data = pd.read_csv(\"/Users/panhong/Desktop/coding_study/Likelion_KDT/Jupyter_notebook/csv_file/InData_0729_1505.csv\" ,\n",
    "names = [\"1\" , \"2\" , \"3\" , \"4\" , \"5\" , \"6\" , \"7\" , \"8\" , \"9\"])\n",
    "seed = 0 \n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "stright = list(Car_data.pop(\"7\"))\n",
    "back = list(Car_data.pop(\"8\"))\n",
    "trash = Car_data.pop(\"9\")\n",
    "\n",
    "i = 0\n",
    "Go_Back = []\n",
    "while i < len(stright):\n",
    "    if stright[i] + back[i] < 1:\n",
    "        Go_Back.append(0)\n",
    "    else:\n",
    "        Go_Back.append(1)\n",
    "    i += 1\n",
    "\n",
    "Car_data[\"7\"] = Go_Back\n",
    "Car_data[\"8\"] = trash\n",
    "\n",
    "dataset = Car_data.values\n",
    "\n",
    "x_data = dataset[: , :7]\n",
    "y_data = dataset[: , 7]\n",
    "y_data = tf.keras.utils.to_categorical(y_data)\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x_data , y_data , test_size = 0.3 , random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf928036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/44 [===========>..................] - ETA: 0s - loss: 1.0437 - acc: 0.6468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 16:10:27.176453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 12ms/step - loss: 0.8848 - acc: 0.6873 - val_loss: 0.6616 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66157, saving model to ./model_freecar/01-0.6616.hdf5\n",
      "Epoch 2/1000\n",
      " 7/44 [===>..........................] - ETA: 0s - loss: 0.6650 - acc: 0.7386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 16:10:27.626174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 11ms/step - loss: 0.6607 - acc: 0.7324 - val_loss: 0.5923 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66157 to 0.59234, saving model to ./model_freecar/02-0.5923.hdf5\n",
      "Epoch 3/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.6247 - acc: 0.7436 - val_loss: 0.6510 - val_acc: 0.7440\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59234\n",
      "Epoch 4/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.6288 - acc: 0.7490 - val_loss: 0.5923 - val_acc: 0.7430\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59234 to 0.59233, saving model to ./model_freecar/04-0.5923.hdf5\n",
      "Epoch 5/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5860 - acc: 0.7606 - val_loss: 0.5619 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59233 to 0.56193, saving model to ./model_freecar/05-0.5619.hdf5\n",
      "Epoch 6/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5773 - acc: 0.7629 - val_loss: 0.5517 - val_acc: 0.7594\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56193 to 0.55169, saving model to ./model_freecar/06-0.5517.hdf5\n",
      "Epoch 7/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5562 - acc: 0.7743 - val_loss: 0.5410 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.55169 to 0.54104, saving model to ./model_freecar/07-0.5410.hdf5\n",
      "Epoch 8/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5789 - acc: 0.7702 - val_loss: 0.5452 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54104\n",
      "Epoch 9/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5569 - acc: 0.7711 - val_loss: 0.5458 - val_acc: 0.7770\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54104\n",
      "Epoch 10/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5275 - acc: 0.7873 - val_loss: 0.5251 - val_acc: 0.7918\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54104 to 0.52506, saving model to ./model_freecar/10-0.5251.hdf5\n",
      "Epoch 11/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5316 - acc: 0.7864 - val_loss: 0.5200 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.52506 to 0.52004, saving model to ./model_freecar/11-0.5200.hdf5\n",
      "Epoch 12/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5167 - acc: 0.7934 - val_loss: 0.5306 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.52004\n",
      "Epoch 13/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5303 - acc: 0.7816 - val_loss: 0.5536 - val_acc: 0.7908\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52004\n",
      "Epoch 14/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5124 - acc: 0.7953 - val_loss: 0.5074 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52004 to 0.50737, saving model to ./model_freecar/14-0.5074.hdf5\n",
      "Epoch 15/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5180 - acc: 0.7907 - val_loss: 0.5081 - val_acc: 0.8003\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.50737\n",
      "Epoch 16/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5136 - acc: 0.7964 - val_loss: 0.5021 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.50737 to 0.50210, saving model to ./model_freecar/16-0.5021.hdf5\n",
      "Epoch 17/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5031 - acc: 0.7925 - val_loss: 0.5012 - val_acc: 0.7913\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.50210 to 0.50117, saving model to ./model_freecar/17-0.5012.hdf5\n",
      "Epoch 18/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4998 - acc: 0.7969 - val_loss: 0.5148 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.50117\n",
      "Epoch 19/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5035 - acc: 0.7930 - val_loss: 0.5167 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.50117\n",
      "Epoch 20/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4998 - acc: 0.7975 - val_loss: 0.5112 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.50117\n",
      "Epoch 21/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4947 - acc: 0.7978 - val_loss: 0.5230 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.50117\n",
      "Epoch 22/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.5047 - acc: 0.8035 - val_loss: 0.5266 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.50117\n",
      "Epoch 23/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4950 - acc: 0.7975 - val_loss: 0.4817 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.50117 to 0.48165, saving model to ./model_freecar/23-0.4817.hdf5\n",
      "Epoch 24/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4841 - acc: 0.8071 - val_loss: 0.5031 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48165\n",
      "Epoch 25/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4873 - acc: 0.8057 - val_loss: 0.4935 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48165\n",
      "Epoch 26/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4772 - acc: 0.8037 - val_loss: 0.4976 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.48165\n",
      "Epoch 27/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4735 - acc: 0.8130 - val_loss: 0.4964 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48165\n",
      "Epoch 28/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4813 - acc: 0.8048 - val_loss: 0.4846 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.48165\n",
      "Epoch 29/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4651 - acc: 0.8092 - val_loss: 0.4995 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48165\n",
      "Epoch 30/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4744 - acc: 0.8046 - val_loss: 0.5182 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.48165\n",
      "Epoch 31/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4735 - acc: 0.8041 - val_loss: 0.4904 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.48165\n",
      "Epoch 32/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4761 - acc: 0.8085 - val_loss: 0.4959 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.48165\n",
      "Epoch 33/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4700 - acc: 0.8137 - val_loss: 0.4846 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.48165\n",
      "Epoch 34/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4654 - acc: 0.8123 - val_loss: 0.4951 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.48165\n",
      "Epoch 35/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4581 - acc: 0.8162 - val_loss: 0.4918 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.48165\n",
      "Epoch 36/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4787 - acc: 0.8073 - val_loss: 0.5080 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.48165\n",
      "Epoch 37/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4711 - acc: 0.8112 - val_loss: 0.5026 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.48165\n",
      "Epoch 38/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4621 - acc: 0.8135 - val_loss: 0.4842 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.48165\n",
      "Epoch 39/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4620 - acc: 0.8123 - val_loss: 0.4951 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.48165\n",
      "Epoch 40/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4585 - acc: 0.8153 - val_loss: 0.4929 - val_acc: 0.8056\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.48165\n",
      "Epoch 41/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4582 - acc: 0.8162 - val_loss: 0.4979 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.48165\n",
      "Epoch 42/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4590 - acc: 0.8080 - val_loss: 0.4832 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.48165\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4545 - acc: 0.8144 - val_loss: 0.4809 - val_acc: 0.8030\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.48165 to 0.48086, saving model to ./model_freecar/43-0.4809.hdf5\n",
      "Epoch 44/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4534 - acc: 0.8194 - val_loss: 0.4915 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.48086\n",
      "Epoch 45/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4650 - acc: 0.8123 - val_loss: 0.4897 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.48086\n",
      "Epoch 46/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4552 - acc: 0.8148 - val_loss: 0.5112 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.48086\n",
      "Epoch 47/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4499 - acc: 0.8201 - val_loss: 0.4765 - val_acc: 0.7993\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.48086 to 0.47647, saving model to ./model_freecar/47-0.4765.hdf5\n",
      "Epoch 48/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4472 - acc: 0.8178 - val_loss: 0.4931 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.47647\n",
      "Epoch 49/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4509 - acc: 0.8194 - val_loss: 0.4990 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.47647\n",
      "Epoch 50/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4498 - acc: 0.8189 - val_loss: 0.4896 - val_acc: 0.8046\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.47647\n",
      "Epoch 51/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4547 - acc: 0.8174 - val_loss: 0.4914 - val_acc: 0.8030\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.47647\n",
      "Epoch 52/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4521 - acc: 0.8169 - val_loss: 0.4870 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.47647\n",
      "Epoch 53/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4553 - acc: 0.8187 - val_loss: 0.5032 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.47647\n",
      "Epoch 54/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4559 - acc: 0.8123 - val_loss: 0.4885 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.47647\n",
      "Epoch 55/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4525 - acc: 0.8153 - val_loss: 0.5102 - val_acc: 0.7918\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.47647\n",
      "Epoch 56/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4560 - acc: 0.8221 - val_loss: 0.4874 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.47647\n",
      "Epoch 57/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4534 - acc: 0.8196 - val_loss: 0.4874 - val_acc: 0.8035\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.47647\n",
      "Epoch 58/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4513 - acc: 0.8194 - val_loss: 0.4872 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.47647\n",
      "Epoch 59/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4451 - acc: 0.8246 - val_loss: 0.4826 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.47647\n",
      "Epoch 60/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4535 - acc: 0.8199 - val_loss: 0.4835 - val_acc: 0.8046\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.47647\n",
      "Epoch 61/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4387 - acc: 0.8258 - val_loss: 0.4928 - val_acc: 0.7982\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.47647\n",
      "Epoch 62/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4430 - acc: 0.8201 - val_loss: 0.4800 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.47647\n",
      "Epoch 63/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4366 - acc: 0.8212 - val_loss: 0.4839 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.47647\n",
      "Epoch 64/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4498 - acc: 0.8103 - val_loss: 0.4991 - val_acc: 0.7950\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.47647\n",
      "Epoch 65/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4554 - acc: 0.8112 - val_loss: 0.5031 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.47647\n",
      "Epoch 66/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4444 - acc: 0.8228 - val_loss: 0.4945 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.47647\n",
      "Epoch 67/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4569 - acc: 0.8146 - val_loss: 0.4871 - val_acc: 0.7971\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.47647\n",
      "Epoch 68/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4427 - acc: 0.8219 - val_loss: 0.4708 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.47647 to 0.47081, saving model to ./model_freecar/68-0.4708.hdf5\n",
      "Epoch 69/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4386 - acc: 0.8256 - val_loss: 0.4801 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.47081\n",
      "Epoch 70/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4462 - acc: 0.8185 - val_loss: 0.5202 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.47081\n",
      "Epoch 71/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4520 - acc: 0.8215 - val_loss: 0.4889 - val_acc: 0.7993\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.47081\n",
      "Epoch 72/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4392 - acc: 0.8196 - val_loss: 0.4715 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.47081\n",
      "Epoch 73/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4408 - acc: 0.8189 - val_loss: 0.4756 - val_acc: 0.8056\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.47081\n",
      "Epoch 74/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4368 - acc: 0.8217 - val_loss: 0.4716 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.47081\n",
      "Epoch 75/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4281 - acc: 0.8281 - val_loss: 0.4667 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.47081 to 0.46674, saving model to ./model_freecar/75-0.4667.hdf5\n",
      "Epoch 76/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4400 - acc: 0.8224 - val_loss: 0.4949 - val_acc: 0.8030\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.46674\n",
      "Epoch 77/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4412 - acc: 0.8221 - val_loss: 0.4694 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.46674\n",
      "Epoch 78/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4347 - acc: 0.8226 - val_loss: 0.4884 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.46674\n",
      "Epoch 79/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4370 - acc: 0.8233 - val_loss: 0.4926 - val_acc: 0.8104\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.46674\n",
      "Epoch 80/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4332 - acc: 0.8240 - val_loss: 0.4717 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.46674\n",
      "Epoch 81/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4291 - acc: 0.8303 - val_loss: 0.4877 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.46674\n",
      "Epoch 82/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4317 - acc: 0.8258 - val_loss: 0.4850 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.46674\n",
      "Epoch 83/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4411 - acc: 0.8199 - val_loss: 0.4686 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.46674\n",
      "Epoch 84/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4325 - acc: 0.8228 - val_loss: 0.4759 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.46674\n",
      "Epoch 85/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4437 - acc: 0.8183 - val_loss: 0.4723 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.46674\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4284 - acc: 0.8269 - val_loss: 0.4871 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.46674\n",
      "Epoch 87/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4324 - acc: 0.8240 - val_loss: 0.4670 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.46674\n",
      "Epoch 88/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4368 - acc: 0.8256 - val_loss: 0.5134 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.46674\n",
      "Epoch 89/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4534 - acc: 0.8160 - val_loss: 0.4706 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.46674\n",
      "Epoch 90/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4318 - acc: 0.8258 - val_loss: 0.4800 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.46674\n",
      "Epoch 91/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4270 - acc: 0.8230 - val_loss: 0.4822 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.46674\n",
      "Epoch 92/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4268 - acc: 0.8260 - val_loss: 0.4831 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.46674\n",
      "Epoch 93/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4331 - acc: 0.8212 - val_loss: 0.5027 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.46674\n",
      "Epoch 94/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4267 - acc: 0.8242 - val_loss: 0.4618 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.46674 to 0.46184, saving model to ./model_freecar/94-0.4618.hdf5\n",
      "Epoch 95/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4205 - acc: 0.8278 - val_loss: 0.4776 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.46184\n",
      "Epoch 96/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4360 - acc: 0.8242 - val_loss: 0.4903 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.46184\n",
      "Epoch 97/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4330 - acc: 0.8297 - val_loss: 0.4883 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.46184\n",
      "Epoch 98/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4226 - acc: 0.8240 - val_loss: 0.4811 - val_acc: 0.8046\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.46184\n",
      "Epoch 99/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4317 - acc: 0.8226 - val_loss: 0.4735 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.46184\n",
      "Epoch 100/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4251 - acc: 0.8237 - val_loss: 0.4815 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.46184\n",
      "Epoch 101/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4332 - acc: 0.8258 - val_loss: 0.4817 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.46184\n",
      "Epoch 102/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4267 - acc: 0.8224 - val_loss: 0.4605 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.46184 to 0.46046, saving model to ./model_freecar/102-0.4605.hdf5\n",
      "Epoch 103/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4232 - acc: 0.8287 - val_loss: 0.4777 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.46046\n",
      "Epoch 104/1000\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4200 - acc: 0.8258 - val_loss: 0.5144 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.46046\n",
      "Epoch 105/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4301 - acc: 0.8251 - val_loss: 0.5040 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.46046\n",
      "Epoch 106/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4199 - acc: 0.8278 - val_loss: 0.4659 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.46046\n",
      "Epoch 107/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4278 - acc: 0.8267 - val_loss: 0.5146 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.46046\n",
      "Epoch 108/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4290 - acc: 0.8230 - val_loss: 0.4755 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.46046\n",
      "Epoch 109/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4302 - acc: 0.8237 - val_loss: 0.4779 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.46046\n",
      "Epoch 110/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4235 - acc: 0.8299 - val_loss: 0.4636 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.46046\n",
      "Epoch 111/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4391 - acc: 0.8226 - val_loss: 0.4945 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.46046\n",
      "Epoch 112/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4159 - acc: 0.8267 - val_loss: 0.4760 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.46046\n",
      "Epoch 113/1000\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4195 - acc: 0.8315 - val_loss: 0.4739 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.46046\n",
      "Epoch 114/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4233 - acc: 0.8328 - val_loss: 0.4741 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.46046\n",
      "Epoch 115/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4248 - acc: 0.8267 - val_loss: 0.5011 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.46046\n",
      "Epoch 116/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4156 - acc: 0.8349 - val_loss: 0.4910 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.46046\n",
      "Epoch 117/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4238 - acc: 0.8276 - val_loss: 0.4950 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.46046\n",
      "Epoch 118/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4287 - acc: 0.8290 - val_loss: 0.4948 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.46046\n",
      "Epoch 119/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4194 - acc: 0.8303 - val_loss: 0.4931 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.46046\n",
      "Epoch 120/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4130 - acc: 0.8367 - val_loss: 0.5023 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.46046\n",
      "Epoch 121/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4227 - acc: 0.8283 - val_loss: 0.4859 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.46046\n",
      "Epoch 122/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4112 - acc: 0.8315 - val_loss: 0.5002 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.46046\n",
      "Epoch 123/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4197 - acc: 0.8358 - val_loss: 0.4944 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.46046\n",
      "Epoch 124/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4174 - acc: 0.8290 - val_loss: 0.4674 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.46046\n",
      "Epoch 125/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4088 - acc: 0.8326 - val_loss: 0.4701 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.46046\n",
      "Epoch 126/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4194 - acc: 0.8278 - val_loss: 0.4776 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.46046\n",
      "Epoch 127/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4156 - acc: 0.8333 - val_loss: 0.4768 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.46046\n",
      "Epoch 128/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4232 - acc: 0.8322 - val_loss: 0.4982 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.46046\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4296 - acc: 0.8276 - val_loss: 0.4944 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.46046\n",
      "Epoch 130/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4202 - acc: 0.8281 - val_loss: 0.4801 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.46046\n",
      "Epoch 131/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4211 - acc: 0.8219 - val_loss: 0.4895 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.46046\n",
      "Epoch 132/1000\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4288 - acc: 0.8283 - val_loss: 0.4872 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.46046\n",
      "Epoch 133/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4174 - acc: 0.8278 - val_loss: 0.5034 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.46046\n",
      "Epoch 134/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4269 - acc: 0.8265 - val_loss: 0.4853 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.46046\n",
      "Epoch 135/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4160 - acc: 0.8301 - val_loss: 0.4800 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.46046\n",
      "Epoch 136/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4088 - acc: 0.8347 - val_loss: 0.4867 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.46046\n",
      "Epoch 137/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4111 - acc: 0.8326 - val_loss: 0.5196 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.46046\n",
      "Epoch 138/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4203 - acc: 0.8301 - val_loss: 0.4779 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.46046\n",
      "Epoch 139/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4160 - acc: 0.8360 - val_loss: 0.4953 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.46046\n",
      "Epoch 140/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4158 - acc: 0.8312 - val_loss: 0.4784 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.46046\n",
      "Epoch 141/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4118 - acc: 0.8326 - val_loss: 0.4902 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.46046\n",
      "Epoch 142/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4078 - acc: 0.8369 - val_loss: 0.4997 - val_acc: 0.8184\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.46046\n",
      "Epoch 143/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4205 - acc: 0.8287 - val_loss: 0.5053 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.46046\n",
      "Epoch 144/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4163 - acc: 0.8344 - val_loss: 0.4742 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.46046\n",
      "Epoch 145/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4107 - acc: 0.8358 - val_loss: 0.5037 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.46046\n",
      "Epoch 146/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4081 - acc: 0.8333 - val_loss: 0.4893 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.46046\n",
      "Epoch 147/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4044 - acc: 0.8340 - val_loss: 0.4808 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.46046\n",
      "Epoch 148/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4078 - acc: 0.8287 - val_loss: 0.4980 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.46046\n",
      "Epoch 149/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4047 - acc: 0.8315 - val_loss: 0.4909 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.46046\n",
      "Epoch 150/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4191 - acc: 0.8297 - val_loss: 0.5106 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.46046\n",
      "Epoch 151/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4132 - acc: 0.8271 - val_loss: 0.4770 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.46046\n",
      "Epoch 152/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3980 - acc: 0.8338 - val_loss: 0.4898 - val_acc: 0.8269\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.46046\n",
      "Epoch 153/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4059 - acc: 0.8335 - val_loss: 0.4992 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.46046\n",
      "Epoch 154/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4093 - acc: 0.8342 - val_loss: 0.4828 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.46046\n",
      "Epoch 155/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4197 - acc: 0.8276 - val_loss: 0.5088 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.46046\n",
      "Epoch 156/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4075 - acc: 0.8353 - val_loss: 0.4954 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.46046\n",
      "Epoch 157/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4085 - acc: 0.8360 - val_loss: 0.4814 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.46046\n",
      "Epoch 158/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4100 - acc: 0.8333 - val_loss: 0.5237 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.46046\n",
      "Epoch 159/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4068 - acc: 0.8347 - val_loss: 0.4835 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.46046\n",
      "Epoch 160/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4002 - acc: 0.8360 - val_loss: 0.4793 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.46046\n",
      "Epoch 161/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4157 - acc: 0.8303 - val_loss: 0.4867 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.46046\n",
      "Epoch 162/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4203 - acc: 0.8315 - val_loss: 0.5082 - val_acc: 0.8093\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.46046\n",
      "Epoch 163/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4041 - acc: 0.8294 - val_loss: 0.4978 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.46046\n",
      "Epoch 164/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4035 - acc: 0.8351 - val_loss: 0.5060 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.46046\n",
      "Epoch 165/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4073 - acc: 0.8333 - val_loss: 0.4816 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.46046\n",
      "Epoch 166/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4244 - acc: 0.8322 - val_loss: 0.4871 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.46046\n",
      "Epoch 167/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4016 - acc: 0.8383 - val_loss: 0.4851 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.46046\n",
      "Epoch 168/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4042 - acc: 0.8349 - val_loss: 0.4702 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.46046\n",
      "Epoch 169/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3971 - acc: 0.8390 - val_loss: 0.4960 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.46046\n",
      "Epoch 170/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4088 - acc: 0.8360 - val_loss: 0.4818 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.46046\n",
      "Epoch 171/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4079 - acc: 0.8340 - val_loss: 0.4910 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.46046\n",
      "Epoch 172/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4024 - acc: 0.8358 - val_loss: 0.4926 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.46046\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4134 - acc: 0.8333 - val_loss: 0.4962 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.46046\n",
      "Epoch 174/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4112 - acc: 0.8306 - val_loss: 0.4745 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.46046\n",
      "Epoch 175/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4104 - acc: 0.8322 - val_loss: 0.4954 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.46046\n",
      "Epoch 176/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4001 - acc: 0.8306 - val_loss: 0.4808 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.46046\n",
      "Epoch 177/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4069 - acc: 0.8365 - val_loss: 0.4896 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.46046\n",
      "Epoch 178/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4005 - acc: 0.8328 - val_loss: 0.4801 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.46046\n",
      "Epoch 179/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4021 - acc: 0.8390 - val_loss: 0.4734 - val_acc: 0.8306\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.46046\n",
      "Epoch 180/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4038 - acc: 0.8367 - val_loss: 0.4876 - val_acc: 0.8205\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.46046\n",
      "Epoch 181/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4036 - acc: 0.8297 - val_loss: 0.4921 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.46046\n",
      "Epoch 182/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4068 - acc: 0.8317 - val_loss: 0.5011 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.46046\n",
      "Epoch 183/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4005 - acc: 0.8381 - val_loss: 0.4869 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.46046\n",
      "Epoch 184/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3965 - acc: 0.8342 - val_loss: 0.4792 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.46046\n",
      "Epoch 185/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3987 - acc: 0.8399 - val_loss: 0.4895 - val_acc: 0.8210\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.46046\n",
      "Epoch 186/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3918 - acc: 0.8406 - val_loss: 0.4961 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.46046\n",
      "Epoch 187/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3974 - acc: 0.8374 - val_loss: 0.4971 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.46046\n",
      "Epoch 188/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3920 - acc: 0.8397 - val_loss: 0.5274 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.46046\n",
      "Epoch 189/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4050 - acc: 0.8299 - val_loss: 0.5285 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.46046\n",
      "Epoch 190/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4071 - acc: 0.8328 - val_loss: 0.5014 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.46046\n",
      "Epoch 191/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4013 - acc: 0.8342 - val_loss: 0.4696 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.46046\n",
      "Epoch 192/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3973 - acc: 0.8392 - val_loss: 0.4963 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.46046\n",
      "Epoch 193/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3994 - acc: 0.8388 - val_loss: 0.5431 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.46046\n",
      "Epoch 194/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4068 - acc: 0.8351 - val_loss: 0.5450 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.46046\n",
      "Epoch 195/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4087 - acc: 0.8326 - val_loss: 0.4980 - val_acc: 0.8163\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.46046\n",
      "Epoch 196/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4041 - acc: 0.8310 - val_loss: 0.4865 - val_acc: 0.8269\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.46046\n",
      "Epoch 197/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4007 - acc: 0.8369 - val_loss: 0.4695 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.46046\n",
      "Epoch 198/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4043 - acc: 0.8376 - val_loss: 0.4916 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.46046\n",
      "Epoch 199/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3984 - acc: 0.8347 - val_loss: 0.4994 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.46046\n",
      "Epoch 200/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4033 - acc: 0.8322 - val_loss: 0.4732 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.46046\n",
      "Epoch 201/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.4088 - acc: 0.8294 - val_loss: 0.4965 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.46046\n",
      "Epoch 202/1000\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.3999 - acc: 0.8360 - val_loss: 0.4781 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.46046\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 0.4781 - acc: 0.8152\n",
      " : 0.8152\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30 , input_dim = 7 , activation = \"relu\"))\n",
    "model.add(Dense(30 , activation = \"relu\"))\n",
    "model.add(Dense(4 , activation = \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\" , optimizer = optimizers.Adam(lr = 0.01) , metrics = [\"acc\"])\n",
    "\n",
    "Model_dir = \"./model_freecar/\"\n",
    "if not os.path.exists(Model_dir):\n",
    "    os.mkdir(Model_dir)\n",
    "    \n",
    "modelpath = \"./model_freecar/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath = modelpath , monitor = \"val_loss\" , verbose = 1 , save_best_only = True)\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\" , patience = 100)\n",
    "\n",
    "hist = model.fit(x_train , y_train , epochs = 1000 , batch_size = 100 , validation_data = (x_test , y_test) , verbose = 1 , callbacks = [checkpoint , early_stop])\n",
    "\n",
    "test_loss , test_acc = model.evaluate(x_test , y_test , verbose = 1)\n",
    "\n",
    "print(\" : {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6637909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = hist.history[\"loss\"]\n",
    "accuracy = hist.history[\"acc\"]\n",
    "\n",
    "plt.figure(figsize = (5 , 5))\n",
    "plt.plot(loss , marker = \".\" , c = \"red\" , label = \"loss\")\n",
    "plt.plot(accuracy , marker = \".\" , c = \"blue\" , label = \"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "620ee486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 30)                240       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 1,294\n",
      "Trainable params: 1,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 16:12:56.998605: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.8535665e-13, 7.7450043e-01, 1.9982447e-01, ..., 1.0194522e-02,\n",
       "       9.5701808e-01, 3.2787330e-02], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.predict(x_test).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python39564bitbasecondaff88d2da3a154ebfb639a042a46a85ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
