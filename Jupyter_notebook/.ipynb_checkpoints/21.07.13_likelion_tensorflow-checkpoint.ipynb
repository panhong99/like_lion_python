{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab988c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 모델을 로드해온 파일의 경로 \n",
    "# https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3\n",
    "\n",
    "# interpreter 변수를 생성해 다운로드 받았던 tflite모델의 경로를 입력해준다.\n",
    "interpreter = tf.lite.Interpreter(model_path = \"/Users/panhong/Downloads/lite-model_movenet_singlepose_lightning_3.tflite\")\n",
    "\n",
    "# interpreter내부의 텐서들을 초기화 시켜준다. \n",
    "# tflite를 사용하려면 꼭 설정해주어야 하는 구문이다.\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# cv2.VideoCapture 함수는 비디오파일의 경로를 입력해주면 비디오 파일을 열어서 motion_tracaking을 사용할수도 있고\n",
    "# 본인의 컴퓨터에 웹캡이 존재한다면 경로가 들어가는 공간에 숫자 0을 넣어주면 \n",
    "# 웹캠을 통해서 실시간으로 본인의 motion 또한 tracking을 할 수 있다.\n",
    "cap = cv2.VideoCapture(\"/Users/panhong/Desktop/baseball/김진욱.mov\")\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# is.Opened함수를 사용해서 비디오 파일이 제대로 출력이 되고있는지 확인하는 함수이다.\n",
    "while cap.isOpened():\n",
    "    # 제대로 출력이 되고 있다면 자연스럽게 ret , frame 변수에 각각의 값이 할당이 될것이다.\n",
    "    # 출력이 되었다면 ret = True가 되고 , frame은 영상의 이미지가 담긴다.\n",
    "    ret , frame = cap.read()\n",
    "    \n",
    "    # 비디오 파일이 제대로 출력이 되고 있지 않다면 \"영상이 올바르게 출력되지 않았습니다.\" 라는 문구를 출력하고 반복문을 종료한다.\n",
    "    if not ret:\n",
    "        print(\"영상이 올바르게 출력되지 않았습니다.\")\n",
    "        break\n",
    "    \n",
    "    # cap.get 함수와 cv2.CAP_PROP_FRAME_WIDTH , HEIGHT  , FPS 함수를 이용해서 \n",
    "    # w , h , fps의 변수에 값을 할당\n",
    "    # round함수는 입력받은 숫자를 반올림을 해줌\n",
    "    # 실수형을 정수형으로 만들어 주기 위해서 사용 \n",
    "    # fps함수는 입력되는 영상의 초당 frame수를 가져온다. (초당 프레임수란 영상이 1초당 출력하는 이미지의 개수를 뜻한다.)\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # 영상을 저장해주기 위해서 videowriter함수를 사용 \n",
    "    # fourcc란 저장될 영상의 코덱을 의미함\n",
    "    # 코덱이란 디지털 비디오와 오디오를 위한 압축/복원 기술을 의미함\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "\n",
    "    # 영상의 초당프레임수를 가져옴\n",
    "    # delay의 결과가 30이라면 해당 영상의 초당 출력하는 \n",
    "    # 이미지의 수는 30개란 뜻임\n",
    "    delay = round(1000 / fps)\n",
    "    \n",
    "    # videowriter함수를 이용해서 out변수에 저장\n",
    "    # 1.저장될 영상의 이름  2.코덱  3.초당 프레임  4.width , height\n",
    "    out = cv2.VideoWriter('hello.avi', fourcc, fps, (w, h))\n",
    "    \n",
    "    # 색상이 반전된 영상출력\n",
    "    inversed = ~frame # 반전\n",
    "\n",
    "    # 윤관선만 인식하는 영상출력\n",
    "    edge = cv2.Canny(frame, 50, 150)\n",
    "    \n",
    "    # 윤곽선은 그레이스케일 영상이므로 저장이 불가능 , 컬러영상으로 변경 후 저장\n",
    "    edge_color = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # 영상의 데이터만 저장 , 소리는 x\n",
    "    out.write(edge_color)\n",
    "\n",
    "    # Reshape image (입력될 이미지를 재구성)\n",
    "    # 모델을 가져온 링크를 타고 들어가면 해당 모델의 input값은 float32 , 192 * 192 * 3이므로 \n",
    "    # 가져올 이미지나 비디오를 input모델에 맞게 새롭게 구성을 해주어야 한다.\n",
    "    # 이것은 로드한 모델의 규칙이기 때문에 어겨서는 안된다.\n",
    "    \n",
    "    # 이미지 변수에 frame(cap에서 가져온 비디오의 frame).copy함수를 사용해서 값을 할당\n",
    "    img = frame.copy()\n",
    "    frame_2 = frame.copy()\n",
    "    frame_2 = cv2.cvtColor(frame_2 , cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # tf.image.resize함수를 이용해서 이미지를 input값이 조건에 맞게 새롭게 설정해준다.\n",
    "    # tf.image_resize함수는 조건에 맞게 이미지의 구조를 변경시켜주는 함수이다.\n",
    "    # 첫번째 인자가 image인데 차원확장을 시켜주는 np.expand_dims함수를 이용해서 img의 차원을 변경시켜준다.\n",
    "    # axis = 0이므로 예를 들어 차원이 (4 , 3 , 2)였다면 (1 , 4 , 3 , 2)으로 차원을 1차원 더 늘려준다.\n",
    "    # 두번쨰 인자는 이미지의 weight , heigth값을 설정해주어야 하는데 각각 192 , 192 차원으로 설정을 해서 조건에 맞추어 주었다.\n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img , axis = 0) , 192 , 192)\n",
    "    \n",
    "    # 텐서를 새로운 형태로 casing해주는 tf.cast함수 \n",
    "    # 첫번째 인자를 입력으로 하고 두번째 인자를 이용해서 첫번쨰 인자의 구조를 바꾸어 준다.\n",
    "    # 현재 같은 경우는 img(frame.copy)를 소주점형태로 변환을 시켜주었다.\n",
    "    # cast같은 경우는 로그함수를 사용해서 분석을 할때도 사용했었는데 어떠한 조건이 없는걸로 보아서는 \n",
    "    # True , False로 출력하는 것이 아니라 1 , 0으로 실수형태로 출력이 될것같다.\n",
    "    input_image = tf.cast(img , dtype = tf.float32)\n",
    "     \n",
    "    # Setup input and output\n",
    "    # 가져온 모델(상단의 interpreter)의 입력과 출력의 세부 정보를 가져오는 함수이다.\n",
    "    # tflite모델을 사용할때는 코드를 작성하기 이전에 먼저 이렇게 입력과 출력의 세부사항을 찍어서 확인한 다음에\n",
    "    # 코드를 작성하는것이 좋다. (강조)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Make predictions\n",
    "    # 입력 세부 정보를 입력 이미지와 동일하게 설정\n",
    "    interpreter.set_tensor(input_details[0][\"index\"] , np.array(input_image))\n",
    "    \n",
    "    # 예측을 호출(?) 하고\n",
    "    # invoke를 호출함으로서 마지막함수인 interpreter.get_tensor의 값을 가져올수 있다.\n",
    "    # 이 값은 표현하자면 이미지나 영사에서 감지된 관절의 위치 좌표와 탐색해서 나온결과의 신뢰도 세트를 출력해준다.\n",
    "    # 좌표와 신뢰도 세트는 [0.28992683, 0.37796742, 0.39410055] 이렇게 요소가 총 3개인 리스트로 출력이 된다.\n",
    "    # 그리고 이 데이터세트가 어떤 관절부위를 나타내는지 알 수 있는 방법은 모델을 가져온 페이지에서 확인할 수 있다.\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # 출력 세부정보를 얻어온다. (1 , 1, 17 , 3)으로 이루어진 탐색된 관절의 좌표와 신뢰도세트\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    print(keypoints_with_scores)\n",
    "    \n",
    "    \n",
    "    # Rendering(frame에 motion_tracking 적용)\n",
    "    \n",
    "    # 해당 함수는 아래 작성을 했던 draw_keypoints함수이다. \n",
    "    # 필요한 인자로는 점이 찍힐 이미지 , 점을 찍을 좌표 , 탐색한 관절위치에 대한 신뢰도로 구성이 되어있다.\n",
    "    # 신뢰도를 0.4로 지정해준 이유는 아래의 데이터셋에서 확인해보았을때 평균적으로 0.4이상이었기때문에 \n",
    "    # 0.4로 지정을 해주었다.(너무 정확하게 관절의 위치를 표현하고자 신뢰도 진입장벽을 높게 잡아버리면 아예 관절의 위치가 나오지 않는경우도 생긴다.)\n",
    "    \n",
    "    # 색상 영상  \n",
    "    draw_keypoints(frame , keypoints_with_scores , 0.4)\n",
    "    draw_keypoints(inversed , keypoints_with_scores , 0.4)\n",
    "    \n",
    "    \n",
    "    # 흑백 영상(흑백은 채널이 없기때문에 기존에 함수를 수정해서 사용해주었다.)\n",
    "    draw_keypoints_black(frame_2 , keypoints_with_scores , 0.4)\n",
    "    draw_keypoints_black(edge , keypoints_with_scores , 0.4)\n",
    "    \n",
    "    \n",
    "    # 해당함수는 아래 작성을 했던 draw_connections함수이다. \n",
    "    # 인자들의 구성은 key_points함수와 같지만 EDGES가 추가되어 있다.\n",
    "    # 자세한 설명을 아래로 가면 볼 수 있다.\n",
    "    \n",
    "    # 색상 영상 \n",
    "    draw_connections(frame , keypoints_with_scores , EDGES , 0.4)\n",
    "    draw_connections(inversed , keypoints_with_scores , EDGES , 0.4)\n",
    "    \n",
    "    # 흑백 영상(흑백은 채널이 없기때문에 기존에 함수를 수정해서 사용해주었다.)\n",
    "    draw_connections_black(frame_2 , keypoints_with_scores , EDGES , 0.4)\n",
    "    draw_connections_black(edge , keypoints_with_scores , EDGES , 0.4)\n",
    "    \n",
    "    \n",
    "    # 위의 모든 구문이 통과가 되면 cv2.imshow함수를 사용해 윈도우의 이름은 첫번째 인자로 지정해주고 , 두번째 인자인\n",
    "    # frame를 출력해준다.\n",
    "    cv2.imshow(\"Movenet Lighting\" , frame)\n",
    "    cv2.imshow(\"black\" , frame_2)\n",
    "    cv2.imshow('inversed', inversed)\n",
    "    cv2.imshow('edge', edge)\n",
    "    \n",
    "    width = cap.get(3)\n",
    "    height = cap.get(4)\n",
    "    \n",
    "    print(width)\n",
    "    print(height)\n",
    "            \n",
    "    # 키보드 이벤트를 설정해준다. 키보드에서 q를 누르면 반복문을 종료하고 모든 윈도우를 제거 해준다.\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "# open한 cap객체를 release함수를 실행해서 반드시 종료시켜준다.\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "inversed.shape\n",
    "\n",
    "# input데이터의 입력세부 구조를 확인\n",
    "# input = 입력구조\n",
    "# 항상 이렇게 먼저 입력구조에 대해서 설정확인을 하고 난 다음 \n",
    "# 입력될 자료의 구조를 조건에 맞게 설정을 해주고 코드 작성을 시작하는 것이 좋다.\n",
    "interpreter.get_input_details()\n",
    "\n",
    "# output데이터의 내부구조를 확인 \n",
    "# output = 출력구조 \n",
    "# 입력조건에 맞추어서 데이터를 입력해주고 나서 출력은\n",
    "# 항상 로드한 모델의 출력조건과 동일하게 출력이 된다.\n",
    "# 현재 모델같은 경우는 출력의 shape는 ([1 , 1  , 17 , 3])으로 출력이된다.\n",
    "interpreter.get_output_details()\n",
    "\n",
    "# 실제 출력이된 결과를 가져와서 확인해보기\n",
    "# 확인해보면 모델의 출력조건과 동일하게 (1 , 1 , 17 , 3) dtype = float32로 출력이 되는것을 확인할수 있다.\n",
    "# 데이터셋의 3번째 요소가 탐색한 관절위치의 신뢰도를 나타내는데 예를 들어 이미지가 정면만 보일경우에는 \n",
    "# 데이터셋 마지막 8개의 데이터셋의 신뢰도는 현저하게 낮아진다. 그럴수밖에 없는것이 마지막 8개의 데이터세트는 \n",
    "# 신체의 후면을 탐지하기 때문에 당연히 정면만 보이는 이미지에서는 신뢰도가 당연히 낮아질수 밖에 없으니 \n",
    "# 혹여나 신뢰도가 너무 낮게 출력이 되었다면 이미지가 정면밖에 보이지 않는것은 아닌지 확인해볼 필요성이 있다.\n",
    "keypoints_with_scores\n",
    "\n",
    "# [nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, \n",
    "# right hip, left knee, right knee, left ankle, right ankle]).\n",
    "# 상단에 표시된 리스트가 바로 마지막 출력이된(keypoints_with_scores)의 데이터세트와 연결지을수 있는 리스트이다.\n",
    "# 상단의 리스트도 총 17개의 객체로 구성되어 있으며 최종출력결과또한 2차원인 요소가 17개가 있다.\n",
    "# 각각 짝을 맞춰 주자면 최종출력결과의 0번째 리스트는 코의 좌표와 신뢰도를 나타내고 5번째 리스트는 좌측어깨의 좌표와 신뢰도를 나타낸다.\n",
    "\n",
    "# 탐색된 좌측어깨의 x , y 좌표와 신뢰도 , # 탐색된 우측어깨의 x , y 좌표와 신뢰도\n",
    "left_sholder = keypoints_with_scores[0][0][5]\n",
    "right_sholder = keypoints_with_scores[0][0][7]\n",
    "\n",
    "left_sholder , right_sholder\n",
    "\n",
    "# 곱해준 480 , 640은 튜토리얼을 인용한것이고 원래 곱해주어야 하는값은 frame.shape의  w , h값을 곱해주어야한다.\n",
    "# 일단 이렇게 표현을 한 이유는 [:2]번까지가 x , y의 좌표이며 int로 나타내주어서 횔씬 시각적으로 인식하기 편하게 해주기 위함이다.\n",
    "np.array(left_sholder[:2] * [608 , 794]).astype(int)\n",
    "\n",
    "# 좌표위치를 파악해서 해당되는 관절의 점을 찍어줄 함수작성 \n",
    "# 점을 찍어주기 위해서 필요한 구성요소들은 (1.점이 찍힐 이미지  2.이미지에 점을 찍을 좌표 , 3.적절한 신뢰도)이다.\n",
    "def draw_keypoints(frame , keypoints , confidence_threshold):\n",
    "    # frame은 이미지이고 이미지를 shape를 하면 heigth , weigth , chnnel(흑 , 색)정보가 출력되고\n",
    "    # 각각의 변수에다 해당되는 값을 할당해줄것이다.\n",
    "    y , x , c = frame.shape\n",
    "    \n",
    "    # 해당 변수의 대한 설명은 바로 아래셀에서 볼수있다.\n",
    "    shaped = np.squeeze(np.multiply(keypoints , [y , x , 1]))\n",
    "    \n",
    "    # shaped값을 kp에 입력\n",
    "    # shaped의 값은 총 17개이기때문에 반복문을 이용해서 모든값을 적용하여 온전하게 점을 찍을수 있도록 해준다. \n",
    "    for kp in shaped:\n",
    "        # shaped의 값을 입력받은 kp의 값을 다시 kx , ky , kp_conf에 개별로 값을 할당시켜준다.\n",
    "        ky , kx , kp_conf = kp\n",
    "        # kp_conf = 신뢰도 confidence = 작성자가 임의로 설정한 신뢰도 기준치\n",
    "        # 신뢰도가 기준치보다 높다면 조건문을 실행\n",
    "        if kp_conf > confidence_threshold:\n",
    "            # cv2.circle는 원을 그려주는 cv2의 함수이다. \n",
    "            # 인수를 설명하자면 \n",
    "            # 1. 원이 그려질 이미지 \n",
    "            # 2. 원을 찍을 좌표\n",
    "            # 2-1 shaped의 설명을 보면 왜 int를 씌워준지 이해를 할수가 있는데 int로 형변환을 시켜주면 보다 정확하게 \n",
    "            # x , y 의 좌표를 가져올수 있기때문에 int로 형변환을 해준것이다.\n",
    "            # 3. 원의 크기를 설정 \n",
    "            # 4. 원의 색을 설정 \n",
    "            # 5. 원의 선의 두께 (음수를 입력하게 되면 4에서 지정한 색으로 원을 채워주게 된다.)\n",
    "            cv2.circle(frame , (int(kx) , int(ky))  , 4 , (0 , 255 , 0) , -1)\n",
    "\n",
    "# 좌표위치를 파악해서 해당되는 관절의 점을 찍어줄 함수작성 \n",
    "# 점을 찍어주기 위해서 필요한 구성요소들은 (1.점이 찍힐 이미지  2.이미지에 점을 찍을 좌표 , 3.적절한 신뢰도)이다.\n",
    "def draw_keypoints_black(frame , keypoints , confidence_threshold):\n",
    "    # frame은 이미지이고 이미지를 shape를 하면 heigth , weigth , chnnel(흑 , 색)정보가 출력되고\n",
    "    # 각각의 변수에다 해당되는 값을 할당해줄것이다.\n",
    "    y , x = frame.shape\n",
    "    \n",
    "    # 해당 변수의 대한 설명은 바로 아래셀에서 볼수있다.\n",
    "    shaped = np.squeeze(np.multiply(keypoints , [y , x , 1]))\n",
    "    \n",
    "    # shaped값을 kp에 입력\n",
    "    # shaped의 값은 총 17개이기때문에 반복문을 이용해서 모든값을 적용하여 온전하게 점을 찍을수 있도록 해준다. \n",
    "    for kp in shaped:\n",
    "        # shaped의 값을 입력받은 kp의 값을 다시 kx , ky , kp_conf에 개별로 값을 할당시켜준다.\n",
    "        ky , kx , kp_conf = kp\n",
    "        # kp_conf = 신뢰도 confidence = 작성자가 임의로 설정한 신뢰도 기준치\n",
    "        # 신뢰도가 기준치보다 높다면 조건문을 실행\n",
    "        if kp_conf > confidence_threshold:\n",
    "            # cv2.circle는 원을 그려주는 cv2의 함수이다. \n",
    "            # 인수를 설명하자면 \n",
    "            # 1. 원이 그려질 이미지 \n",
    "            # 2. 원을 찍을 좌표\n",
    "            # 2-1 shaped의 설명을 보면 왜 int를 씌워준지 이해를 할수가 있는데 int로 형변환을 시켜주면 보다 정확하게 \n",
    "            # x , y 의 좌표를 가져올수 있기때문에 int로 형변환을 해준것이다.\n",
    "            # 3. 원의 크기를 설정 \n",
    "            # 4. 원의 색을 설정 \n",
    "            # 5. 원의 선의 두께 (음수를 입력하게 되면 4에서 지정한 색으로 원을 채워주게 된다.)\n",
    "            cv2.circle(frame , (int(kx) , int(ky))  , 4 , (0 , 255 , 0) , -1)\n",
    "\n",
    "# 상단의 함수에 shaped에 할당되어 있는 식을 전개하면 이런형태가 나오게 된다.\n",
    "# 해석을 하면 우리는 점을 찍을 좌표가 보다 정확하게 입력이 되었으면 하기때문에 출력된 좌표값에 기존의 이미지의 x , y 좌표를\n",
    "# np.multiply 함수를 이용하여 곱해준다. 이렇게 되면 결과가 기계나 사람이 보기에도 횔씬 더 정확하게 판단할수 있는 값이 출력이 나오게 된다.\n",
    "# 마지막에 1을 곱해준 이유는 최종출력에서 좌표와 신뢰도가 출력된다고 했는데 마지막 신뢰도 값에 변화를 주지 않고 그대로 출력을 시키고자\n",
    "# 1을 곱해준것이다.\n",
    "np.squeeze(np.multiply(interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"]) , [480 , 640 , 1]))\n",
    "\n",
    "# [0]번째 배열을 출력하게되면 보다 깔끔하게 출력되는 결과를 볼수있다.(0번째 배열이 나타내는 것은 코의 좌표와 신뢰도)\n",
    "# np.squeeze(np.multiply(interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"]) , [480 , 640 , 1]))[0]\n",
    "\n",
    "# 이렇게 마지막에 int로 형변환을 해주면 좌표의 값은 횔씬 정확하게 출력을 해줄수가 있겠지만 \n",
    "# 마지막 신뢰도는 그대로 실수형이기 때문에 신뢰도가 0으로 출력이 된다. 그렇기때문에 \n",
    "# int로 형변환을 해주지 않고 기존 이미지의 shape값만 곱해주는것이다.\n",
    "# np.squeeze(np.multiply(interpreter.get_tensor(interpreter.get_output_details()[0][\"index\"]) , [480 , 640 , 1])).astype(int)\n",
    "\n",
    "# 해당 딕셔너리를 이용해서 그려진 점들을 선으로 연결시켜주는데 도움을 줄 수가 있다.\n",
    "# 가만히 보면 key부분에는 (0 , 1)이런형식으로 작성이 되어있는데 여기서 나타내는 숫자는 \n",
    "# 각 관절의 위치번호이며 튜플로 묶어져있는 관절의 위치를 라인으로 그려주라는 가이드라고 생각하면 좋을것 같다.\n",
    "# 실제로 관절번호중 0 = 코 , 1 = 좌측안구이며 코에 그려진 원과 좌측안구에 그려진 원을 연결한다.\n",
    "# 아래의 튜플들도 각각 자연스러운 연결을 위해서 적합한 관절끼리 튜플형식으로 묶여져 있다.\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "# 상단의 draw_keypoints와 거의 유사하지만 매개변수에 edges라는 변수가 추가되었다.\n",
    "# 이 함수는 관절에 그려진 원들을 각각 라인으로 연결시켜주기 위해서 작성한 함수이다.\n",
    "def draw_connections(frame , keypoints , edges , confidence_threshold):\n",
    "    # 아래 2줄은 key_points의 함수와 100%같은 코드이다.\n",
    "    y , x , c = frame.shape \n",
    "    shaped = np.squeeze(np.multiply(keypoints , [y , x , 1]))\n",
    "    \n",
    "    # edges.items = 상단에 보이는 딕셔너리를 할당해 줄것이다.\n",
    "    # 그렇게되면 edge에는 key가 들어갈것이며 , color에는 values가 할당될것이다.\n",
    "    # color의 내용은 사용하지 않았다.\n",
    "    for edge , color in edges.items():\n",
    "        # edge의 값은 2개이므로 각각의 값을 p1 , p2로 찢어준다.\n",
    "        p1 , p2 = edge\n",
    "        # shaped값은 상단에 설명이 되어었고 p1 , p2의 값은 관절위치의 정보이므로 \n",
    "        # shaped내에서 p1 , p2에 적용되는 자료들을 불러와 할당을 해줄것이다. \n",
    "        # 자료들은 좌표와 신뢰도이다.\n",
    "        y1 , x1 , c1 = shaped[p1]\n",
    "        y2 , x2 , c2 = shaped[p2]\n",
    "        \n",
    "        # c1 , c2(EDGES에서 명령한 관절위치의 대한 신뢰도)가 각각 지정해놓은 신뢰도 수치보다 높다면 조건문 실행\n",
    "        if(c1 > confidence_threshold) & (c2 > confidence_threshold):\n",
    "            # cv2의 그리기 함수 \n",
    "            # 1. 라인이 그려질 이미지 \n",
    "            # 2. 직선의 시작점과 끝점\n",
    "            # 3. 선의 색상\n",
    "            # 4. 선의 두께\n",
    "            cv2.line(frame , (int(x1) , int(y1))  , (int(x2) , int(y2)) , (255 , 0 , 0)  , 2)\n",
    "\n",
    "# 상단의 draw_keypoints와 거의 유사하지만 매개변수에 edges라는 변수가 추가되었다.\n",
    "# 이 함수는 관절에 그려진 원들을 각각 라인으로 연결시켜주기 위해서 작성한 함수이다.\n",
    "def draw_connections_black(frame , keypoints , edges , confidence_threshold):\n",
    "    # 아래 2줄은 key_points의 함수와 100%같은 코드이다.\n",
    "    y , x = frame.shape \n",
    "    shaped = np.squeeze(np.multiply(keypoints , [y , x , 1]))\n",
    "    \n",
    "    # edges.items = 상단에 보이는 딕셔너리를 할당해 줄것이다.\n",
    "    # 그렇게되면 edge에는 key가 들어갈것이며 , color에는 values가 할당될것이다.\n",
    "    # color의 내용은 사용하지 않았다.\n",
    "    for edge , color in edges.items():\n",
    "        # edge의 값은 2개이므로 각각의 값을 p1 , p2로 찢어준다.\n",
    "        p1 , p2 = edge\n",
    "        # shaped값은 상단에 설명이 되어었고 p1 , p2의 값은 관절위치의 정보이므로 \n",
    "        # shaped내에서 p1 , p2에 적용되는 자료들을 불러와 할당을 해줄것이다. \n",
    "        # 자료들은 좌표와 신뢰도이다.\n",
    "        y1 , x1 , c1 = shaped[p1]\n",
    "        y2 , x2 , c2 = shaped[p2]\n",
    "        \n",
    "        # c1 , c2(EDGES에서 명령한 관절위치의 대한 신뢰도)가 각각 지정해놓은 신뢰도 수치보다 높다면 조건문 실행\n",
    "        if(c1 > confidence_threshold) & (c2 > confidence_threshold):\n",
    "            # cv2의 그리기 함수 \n",
    "            # 1. 라인이 그려질 이미지 \n",
    "            # 2. 직선의 시작점과 끝점\n",
    "            # 3. 선의 색상\n",
    "            # 4. 선의 두께\n",
    "            cv2.line(frame , (int(x1) , int(y1))  , (int(x2) , int(y2)) , (255 , 0 , 0)  , 2)\n",
    "\n",
    "# draw_connection 함수내에 for문 설명\n",
    "# 아래처럼 for문을 작성하면 shaped에 있는 값들이 각각 변수들에 할당이 되어 \n",
    "# 정확하게 라인을 그릴수 있도록 도움을 준다. \n",
    "for edge , color in EDGES.items():\n",
    "    p1 , p2 = edge \n",
    "    y1 , x1 , c1 = shaped[p1]\n",
    "    y2 , x2 , c2 = shaped[p2]\n",
    "    print(y1 , x1 , c1 , y2 , x2 , c2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python39564bitbasecondaff88d2da3a154ebfb639a042a46a85ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
