{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b738f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/panhong/miniforge3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493b4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 300 , a1 = 0.7668 , a2 = -0.4862 , b = -2.4275 , loss = 0.2669\n",
      "step = 600 , a1 = 0.7891 , a2 = -0.2440 , b = -3.9078 , loss = 0.1906\n",
      "step = 900 , a1 = 0.7099 , a2 = 0.0686 , b = -4.9724 , loss = 0.1490\n",
      "step = 1200 , a1 = 0.6129 , a2 = 0.3656 , b = -5.8134 , loss = 0.1221\n",
      "step = 1500 , a1 = 0.5185 , a2 = 0.6323 , b = -6.5106 , loss = 0.1032\n",
      "step = 1800 , a1 = 0.4322 , a2 = 0.8687 , b = -7.1066 , loss = 0.0892\n",
      "step = 2100 , a1 = 0.3551 , a2 = 1.0780 , b = -7.6275 , loss = 0.0785\n",
      "step = 2400 , a1 = 0.2865 , a2 = 1.2642 , b = -8.0901 , loss = 0.0700\n",
      "step = 2700 , a1 = 0.2255 , a2 = 1.4309 , b = -8.5063 , loss = 0.0632\n",
      "step = 3000 , a1 = 0.1712 , a2 = 1.5811 , b = -8.8847 , loss = 0.0575\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "x_data = np.array([[2,3] , [4,3] , [6,4] , [8,6] , [10,7] , [12,8] , [14,9]])\n",
    "y_data = np.array([0,0,0,1,1,1,1]).reshape(7,1)\n",
    "\n",
    "X = tf.placeholder(tf.float64 , shape = [None , 2])\n",
    "Y = tf.placeholder(tf.float64 , shape = [None , 1])\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([2,1] , dtype = tf.float64))\n",
    "b = tf.Variable(tf.random_uniform([1] , dtype = tf.float64))\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(X ,a) + b)\n",
    "\n",
    "loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "predicted = tf.cast(y > 0.5 , dtype = tf.float64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted ,Y) , dtype = tf.float64))\n",
    "\n",
    "with tf.Session() as  sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3001):\n",
    "        a_ , b_ , loss_ , _ = sess.run([a , b ,loss , gradient_decent] , feed_dict = {X : x_data , Y : y_data})\n",
    "        if (i + 1)  % 300 == 0:\n",
    "            print(\"step = %d , a1 = %.4f , a2 = %.4f , b = %.4f , loss = %.4f\" % (i + 1 , a_[0] , a_[1] , b_ , loss_))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab12a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6720257\n",
      "200 0.6242457\n",
      "400 0.6078408\n",
      "600 0.59670633\n",
      "800 0.5871625\n",
      "1000 0.5785743\n",
      "1200 0.5707721\n",
      "1400 0.5636666\n",
      "1600 0.55718684\n",
      "1800 0.5512709\n",
      "2000 0.5458629\n",
      "2200 0.54091305\n",
      "2400 0.53637636\n",
      "2600 0.5322128\n",
      "2800 0.5283865\n",
      "3000 0.52486527\n",
      "3200 0.52162045\n",
      "3400 0.5186262\n",
      "3600 0.5158596\n",
      "3800 0.51329994\n",
      "4000 0.5109288\n",
      "4200 0.5087296\n",
      "4400 0.5066873\n",
      "4600 0.5047884\n",
      "4800 0.50302094\n",
      "5000 0.501374\n",
      "5200 0.49983773\n",
      "5400 0.49840304\n",
      "5600 0.49706197\n",
      "5800 0.49580708\n",
      "6000 0.4946318\n",
      "6200 0.49353\n",
      "6400 0.49249613\n",
      "6600 0.4915253\n",
      "6800 0.49061275\n",
      "7000 0.4897543\n",
      "7200 0.48894608\n",
      "7400 0.4881846\n",
      "7600 0.48746657\n",
      "7800 0.48678908\n",
      "8000 0.48614928\n",
      "8200 0.48554468\n",
      "8400 0.484973\n",
      "8600 0.484432\n",
      "8800 0.48391983\n",
      "9000 0.48343447\n",
      "9200 0.48297438\n",
      "9400 0.48253787\n",
      "9600 0.48212358\n",
      "9800 0.48173007\n",
      "10000 0.48135614\n",
      "Accuracy :  0.7694335\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt(\"/Users/panhong/Desktop/coding_study/Likelion_KDT/Jupyter_notebook/data-03-diabetes.csv\" , delimiter = \",\" , dtype = np.float32)\n",
    "x_data = xy[: , 0:-1]\n",
    "y_data = xy[: , [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32 , shape = [None , 8])\n",
    "Y = tf.placeholder(tf.float32 , shape = [None , 1])\n",
    "\n",
    "# normal은 중앙값이 더 많이 나오게 uniform은 전체적으로 균등하게 나오게\n",
    "\n",
    "w = tf.Variable(tf.random_normal([8,1]) , name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]) , name = \"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X , w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5 , dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted , Y) ,dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val , _ = sess.run([cost , train] , feed_dict = {X : x_data , Y : y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step , cost_val)\n",
    "            \n",
    "    # _는 어떤 특정값 무시하기 위한 용도\n",
    "    _ , _ , a = sess.run([hypothesis , predicted , accuracy] , feed_dict = {X : x_data , Y : y_data})\n",
    "    #a = sess.run(accuracy , feed_dict = {X : x_data , Y : y_data}) # 같이해도 문제는 안됨\n",
    "    #graph가 구성되어 있으므로\n",
    "    print(\"Accuracy : \" , a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "433c8ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  0.76114255 w =  [[-0.7640232 ]\n",
      " [-0.72761285]] b =  [0.20428117]\n",
      "step =  5000 cost =  0.7061111 w =  [[-0.4700519]\n",
      " [-0.443288 ]] b =  [0.4409407]\n",
      "step =  10000 cost =  0.7011977 w =  [[-0.362069  ]\n",
      " [-0.34248668]] b =  [0.40391237]\n",
      "step =  15000 cost =  0.6985987 w =  [[-0.29384443]\n",
      " [-0.27951485]] b =  [0.33826336]\n",
      "step =  20000 cost =  0.6968425 w =  [[-0.24069487]\n",
      " [-0.23020945]] b =  [0.27912498]\n",
      "\n",
      "Hypothesis :  [[0.5693317 ]\n",
      " [0.51222646]\n",
      " [0.50960636]\n",
      " [0.45220158]] \n",
      "Correct :  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy :  0.75\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0] , [0,1] , [1,0] , [1,1]] , dtype = np.float32)\n",
    "y_data = np.array([[1] , [1] , [1] , [0]] , dtype = np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32 , shape = [None,2] , name = \"x-input\")\n",
    "y = tf.placeholder(tf.float32 , shape = [None,1] , name = \"y-input\")\n",
    "\n",
    "w = tf.Variable(tf.random.normal([2 , 1] , name = \"weight\"))\n",
    "b = tf.Variable(tf.random.normal([1]) , name = \"biae\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x , w ) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1 - y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# 소수점으로 된 내용을 1 , 0으로 바꿔주는 함수\n",
    "predicted = tf.cast(hypothesis > 0.5 , dtype = tf.float32)\n",
    "# 양쪽을 비교해서 정확도를 측정해주는 함수 \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y) , dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train ,feed_dict = {x : x_data , y : y_data})\n",
    "        if step % 1000 == 0: \n",
    "            print(\"step = \" , step ,\n",
    "                 \"cost = \" , sess.run(cost , feed_dict = {x : x_data , y : y_data}),\n",
    "                 \"w = \" , sess.run(w) , \"b = \" , sess.run(b))\n",
    "    h , c , a = sess.run([hypothesis , predicted , accuracy],\n",
    "                        feed_dict = {x : x_data , y : y_data})\n",
    "    print(\"\\nHypothesis : \" , h , \"\\nCorrect : \" , c , \"\\nAccuracy : \" , a)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e713b0",
   "metadata": {},
   "source": [
    "nand 는 and의 반대개념 \n",
    "\n",
    "입력 , 출력 , 활성화 함수가 있으면 어떤것도 출력가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46095a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값 : (0, 0)출력 값 : 0\n",
      "입력 값 : (1, 0)출력 값 : 1\n",
      "입력 값 : (0, 1)출력 값 : 1\n",
      "입력 값 : (1, 1)출력 값 : 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11 = np.array([-2,-2])\n",
    "w12 = np.array([2,2])\n",
    "w2 = np.array([1,1])\n",
    "b1 = 3 \n",
    "b2 = -1\n",
    "b3 = -1\n",
    "ㅣㅣ\n",
    "#MLP도 함수 시그모이드 함수를 만들어줌\n",
    "def MLP(x , w , b):\n",
    "    y = np.sum(w * x) + b\n",
    "    if y <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) ,w11 , b1)\n",
    "def OR(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) , w12 , b2)\n",
    "def AND(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) , w2 , b3)\n",
    "def XOR(x1 , x2):\n",
    "    return AND(NAND(x1 , x2) , OR(x1 , x2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for x in [(0,0) , (1,0) , (0,1) , (1,1)]:\n",
    "        y = XOR(x[0] , x[1])\n",
    "        print(\"입력 값 : \" + str(x) + \"출력 값 : \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0687adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 값 : (0, 0)출력 값 : 0\n",
      "입력 값 : (1, 0)출력 값 : 1\n",
      "입력 값 : (0, 1)출력 값 : 1\n",
      "입력 값 : (1, 1)출력 값 : 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w11 = np.array([-7.40,-7.40])\n",
    "w12 = np.array([8.67 , 8.67])\n",
    "w2 = np.array([7.41,7.41])\n",
    "b1 = 11.28\n",
    "b2 = -3.87\n",
    "b3 = -11.29\n",
    "\n",
    "#MLP도 함수 시그모이드 함수를 만들어줌\n",
    "def MLP(x , w , b):\n",
    "    y = 1 / (1 + np.exp(-(np.dot(x , w) + b)))\n",
    "    if y <= 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NAND(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) ,w11 , b1)\n",
    "def OR(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) , w12 , b2)\n",
    "def AND(x1 , x2):\n",
    "    return MLP(np.array([x1 , x2]) , w2 , b3)\n",
    "def XOR(x1 , x2):\n",
    "    return AND(NAND(x1 , x2) , OR(x1 , x2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for x in [(0,0) , (1,0) , (0,1) , (1,1)]:\n",
    "        y = XOR(x[0] , x[1])\n",
    "        print(\"입력 값 : \" + str(x) + \"출력 값 : \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5627f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 cost =  1.0512357 w =  [[-0.8402616]\n",
      " [-0.432978 ]] b =  [-2.0436096]\n",
      "step =  5000 cost =  0.678782 w =  [[-0.8402616]\n",
      " [-0.432978 ]] b =  [-2.0436096]\n",
      "step =  10000 cost =  0.61717296 w =  [[-0.8402616]\n",
      " [-0.432978 ]] b =  [-2.0436096]\n",
      "step =  15000 cost =  0.40911585 w =  [[-0.8402616]\n",
      " [-0.432978 ]] b =  [-2.0436096]\n",
      "step =  20000 cost =  0.21098614 w =  [[-0.8402616]\n",
      " [-0.432978 ]] b =  [-2.0436096]\n",
      "\n",
      "Hypothesis :  [[0.21443279]\n",
      " [0.82397586]\n",
      " [0.82300955]\n",
      " [0.19280808]] \n",
      "Correct :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 다층 퍼셉트론 XOR문제 코드\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0] , [0,1] , [1,0] , [1,1]] , dtype = np.float32)\n",
    "y_data = np.array([[0] , [1] , [1] , [0]] , dtype = np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32 , shape = [None,2] , name = \"x-input\")\n",
    "y = tf.placeholder(tf.float32 , shape = [None,1] , name = \"y-input\")\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2 , 2] , name = \"weight1\"))\n",
    "b1 = tf.Variable(tf.random.normal([1]) , name = \"biae1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(x , w1 ) + b1)\n",
    "#활성화 함수\n",
    "w2 = tf.Variable(tf.random.normal([2 , 1] , name = \"weight2\"))\n",
    "b2 = tf.Variable(tf.random.normal([1]) , name = \"biae2\")\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, w2 ) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1 - y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# 소수점으로 된 내용을 1 , 0으로 바꿔주는 함수\n",
    "predicted = tf.cast(hypothesis > 0.5 , dtype = tf.float32)\n",
    "# 양쪽을 비교해서 정확도를 측정해주는 함수 \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y) , dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20001):\n",
    "        sess.run(train ,feed_dict = {x : x_data , y : y_data})\n",
    "        if step % 5000 == 0: \n",
    "            print(\"step = \" , step ,\n",
    "                 \"cost = \" , sess.run(cost , feed_dict = {x : x_data , y : y_data}),\n",
    "                 \"w = \" , sess.run(w) , \"b = \" , sess.run(b))\n",
    "    h , c , a = sess.run([hypothesis , predicted , accuracy],\n",
    "                        feed_dict = {x : x_data , y : y_data})\n",
    "    print(\"\\nHypothesis : \" , h , \"\\nCorrect : \" , c , \"\\nAccuracy : \" , a)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6a514e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v1.random' has no attribute 'set_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ddf7b56ef397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# w = tf.Variable(tf.random.normal([2 , 1] ,1 , 1, seed = 0,name = \"weight\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v1.random' has no attribute 'set_seed'"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([1] , 0 , 10 , dtype = tf.float64))\n",
    "# w = tf.Variable(tf.random.normal([2 , 1] ,1 , 1, seed = 0,name = \"weight\"))\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(a)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python39564bitbasecondaff88d2da3a154ebfb639a042a46a85ea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
